{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. setting base configuration & params ..\n"
     ]
    }
   ],
   "source": [
    "print(\".. setting base configuration & params ..\")\n",
    "\n",
    "initialize()\n",
    "\n",
    "best_model_filepath = './saved-models/transfer_learning.hdf5'\n",
    "training_epochs = 50\n",
    "batch_size = 20\n",
    "images_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1408 [00:00<02:33,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. loading & splitting data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1408/1408 [00:12<00:00, 110.45it/s]\n",
      "100%|██████████| 440/440 [00:03<00:00, 110.51it/s]\n",
      "100%|██████████| 352/352 [00:03<00:00, 110.30it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_tensors, X_train, y_train,\n",
    "test_tensors, X_test, y_test, \n",
    "valid_tensors, X_validate, y_validate, \n",
    "duration_loading) = load_and_split_data(images_size=images_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# external_model = ResNet50(weights='imagenet', include_top=False)\n",
    "external_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. constructing the transfer model ..\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 326,594\n",
      "Trainable params: 66,178\n",
      "Non-trainable params: 260,416\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmartin/ml/venv/udacity-capstone/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\".. constructing the transfer model ..\")\n",
    "\n",
    "for layer in external_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "temp = Conv2D(filters=128, kernel_size=2, padding='same')(external_model.layers[-13].output)\n",
    "\n",
    "temp = BatchNormalization()(temp)\n",
    "temp = Activation('relu')(temp)\n",
    "temp = MaxPooling2D(pool_size=(2, 2))(temp)\n",
    "temp = GlobalAveragePooling2D()(temp)\n",
    "predictions = Dense(2, activation='softmax')(temp)\n",
    "\n",
    "model = Model(input=external_model.input, output=predictions)\n",
    "\n",
    "model.summary()    \n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. training the model ..\n",
      "Train on 1408 samples, validate on 352 samples\n",
      "Epoch 1/1\n",
      "1408/1408 [==============================] - 686s 487ms/step - loss: 0.3382 - acc: 0.8295 - val_loss: 0.6924 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69241, saving model to ./saved-models/transfer_learning.hdf5\n"
     ]
    }
   ],
   "source": [
    "duration_training = train_single_model(model, \n",
    "                                       best_model_filepath, \n",
    "                                       train_tensors, y_train, \n",
    "                                       valid_tensors, y_validate, \n",
    "                                       training_epochs, \n",
    "                                       batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. loading best weights ..\n"
     ]
    }
   ],
   "source": [
    "print(\".. loading best weights ..\")\n",
    "\n",
    "model.load_weights(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/440 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Test data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [01:34<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Test data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "test_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(test_tensors)]\n",
    "\n",
    "test_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1408 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Training data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1408/1408 [05:04<00:00,  4.69it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Training data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "train_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(train_tensors)]\n",
    "\n",
    "train_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Validation data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:14<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Validation data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "validation_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(valid_tensors)]\n",
    "\n",
    "validation_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "TIMING SUMMARY:\n",
      "\n",
      "loading duration: 22.4 seconds\n",
      "training duration: 686.9 seconds\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON TEST DATA:\n",
      "\n",
      "predict duration: 95.0 seconds\n",
      "all:  440\n",
      "all_positives:  81\n",
      "all_negatives:  359\n",
      "true_positives:  81\n",
      "true_negatives:  206\n",
      "false_positives:  153\n",
      "false_negatives:  0\n",
      "RECALL: 1.00\n",
      "SPECIFICITY: 0.57\n",
      "ACCURACY: 0.65\n",
      "PRECISION: 0.35\n",
      "F1 SCORE: 0.51\n",
      "FP RATE / ERROR I: 0.43\n",
      "FN RATE / ERROR II: 0.00\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON TRAIN DATA:\n",
      "\n",
      "predict duration: 305.0 seconds\n",
      "all:  1408\n",
      "all_positives:  316\n",
      "all_negatives:  1092\n",
      "true_positives:  314\n",
      "true_negatives:  578\n",
      "false_positives:  514\n",
      "false_negatives:  2\n",
      "RECALL: 0.99\n",
      "SPECIFICITY: 0.53\n",
      "ACCURACY: 0.63\n",
      "PRECISION: 0.38\n",
      "F1 SCORE: 0.55\n",
      "FP RATE / ERROR I: 0.47\n",
      "FN RATE / ERROR II: 0.01\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON VALIDATION DATA:\n",
      "\n",
      "predict duration: 74.8 seconds\n",
      "all:  352\n",
      "all_positives:  66\n",
      "all_negatives:  286\n",
      "true_positives:  65\n",
      "true_negatives:  157\n",
      "false_positives:  129\n",
      "false_negatives:  1\n",
      "RECALL: 0.98\n",
      "SPECIFICITY: 0.55\n",
      "ACCURACY: 0.63\n",
      "PRECISION: 0.34\n",
      "F1 SCORE: 0.50\n",
      "FP RATE / ERROR I: 0.45\n",
      "FN RATE / ERROR II: 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"________________________________________________________\")\n",
    "print(\"TIMING SUMMARY:\\n\")\n",
    "print(\"loading duration: {0:.1f} seconds\".format(duration_loading))\n",
    "print(\"training duration: {0:.1f} seconds\".format(duration_training))\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON TEST DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(test_data_predictions_time))\n",
    "false_positive_images, false_negative_images = summarize_model_performance(X_test, y_test, test_data_predictions)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON TRAIN DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(train_data_predictions_time))\n",
    "_, _ = summarize_model_performance(X_train, y_train, train_data_predictions)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON VALIDATION DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(validation_data_predictions_time))\n",
    "_, _ = summarize_model_performance(X_validate, y_validate, validation_data_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Positives (first 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div width='100%'><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-726.jpg:          <img src=\"./data-images/5831135989001-726.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-2246.jpg:          <img src=\"./data-images/5831135989001-2246.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833084561001-1110.jpg:          <img src=\"./data-images/5833084561001-1110.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-324.jpg:          <img src=\"./data-images/5833078851001-324.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139886001-741.jpg:          <img src=\"./data-images/5831139886001-741.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833084561001-1338.jpg:          <img src=\"./data-images/5833084561001-1338.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-2149.jpg:          <img src=\"./data-images/5831135989001-2149.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135399001-2130.jpg:          <img src=\"./data-images/5831135399001-2130.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-2176.jpg:          <img src=\"./data-images/5833078851001-2176.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-206.jpg:          <img src=\"./data-images/5833078851001-206.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135399001-314.jpg:          <img src=\"./data-images/5831135399001-314.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833084561001-1006.jpg:          <img src=\"./data-images/5833084561001-1006.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139883001-2240.jpg:          <img src=\"./data-images/5831139883001-2240.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-620.jpg:          <img src=\"./data-images/5831137888001-620.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-1130.jpg:          <img src=\"./data-images/5831137888001-1130.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135399001-2196.jpg:          <img src=\"./data-images/5831135399001-2196.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139886001-384.jpg:          <img src=\"./data-images/5831139886001-384.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-936.jpg:          <img src=\"./data-images/5831135989001-936.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135399001-1306.jpg:          <img src=\"./data-images/5831135399001-1306.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139883001-1822.jpg:          <img src=\"./data-images/5831139883001-1822.jpg\" style=\"display:inline-block;\"> </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(false_positive_images[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Negatives (first 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div width='100%'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(false_negative_images[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
