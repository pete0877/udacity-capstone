{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. setting base configuration & params ..\n"
     ]
    }
   ],
   "source": [
    "print(\".. setting base configuration & params ..\")\n",
    "\n",
    "initialize()\n",
    "\n",
    "best_model_filepath = './saved-models/achitecture-02.hdf5'\n",
    "training_epochs = 20\n",
    "batch_size = 10\n",
    "images_size = 270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1408 [00:00<00:17, 79.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. loading & splitting data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1408/1408 [00:13<00:00, 101.91it/s]\n",
      "100%|██████████| 440/440 [00:04<00:00, 107.92it/s]\n",
      "100%|██████████| 352/352 [00:03<00:00, 111.12it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_tensors, X_train, y_train,\n",
    "test_tensors, X_test, y_test, \n",
    "valid_tensors, X_validate, y_validate, \n",
    "duration_loading) = load_and_split_data(images_size=images_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. constructing the model ..\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 270, 270, 16)      208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 270, 270, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 270, 270, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 135, 135, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 135, 135, 32)      2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 135, 135, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 135, 135, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 67, 67, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 67, 67, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 67, 67, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 67, 67, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 33, 33, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 33, 33, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 44,658\n",
      "Trainable params: 44,178\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\".. constructing the model ..\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', input_shape=(images_size, images_size, 3), \n",
    "                 data_format=\"channels_last\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. training the model ..\n",
      "Train on 1408 samples, validate on 352 samples\n",
      "Epoch 1/20\n",
      "1408/1408 [==============================] - 418s 297ms/step - loss: 0.3922 - acc: 0.8203 - val_loss: 0.5018 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50176, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 2/20\n",
      "1408/1408 [==============================] - 431s 306ms/step - loss: 0.3152 - acc: 0.8509 - val_loss: 0.9164 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.50176\n",
      "Epoch 3/20\n",
      "1408/1408 [==============================] - 269s 191ms/step - loss: 0.2880 - acc: 0.8707 - val_loss: 1.0046 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50176\n",
      "Epoch 4/20\n",
      "1408/1408 [==============================] - 256s 182ms/step - loss: 0.2705 - acc: 0.8693 - val_loss: 0.2825 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50176 to 0.28250, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 5/20\n",
      "1408/1408 [==============================] - 268s 191ms/step - loss: 0.2434 - acc: 0.8871 - val_loss: 0.2541 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28250 to 0.25410, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 6/20\n",
      "1408/1408 [==============================] - 560s 398ms/step - loss: 0.2454 - acc: 0.8835 - val_loss: 0.2657 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25410\n",
      "Epoch 7/20\n",
      "1408/1408 [==============================] - 2952s 2s/step - loss: 0.2279 - acc: 0.8977 - val_loss: 0.1957 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25410 to 0.19571, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 8/20\n",
      "1408/1408 [==============================] - 292s 208ms/step - loss: 0.2310 - acc: 0.8942 - val_loss: 0.2626 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19571\n",
      "Epoch 9/20\n",
      "1408/1408 [==============================] - 287s 203ms/step - loss: 0.2324 - acc: 0.8935 - val_loss: 0.2418 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19571\n",
      "Epoch 10/20\n",
      "1408/1408 [==============================] - 302s 215ms/step - loss: 0.2260 - acc: 0.9013 - val_loss: 0.1894 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19571 to 0.18935, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 11/20\n",
      "1408/1408 [==============================] - 292s 207ms/step - loss: 0.2197 - acc: 0.8949 - val_loss: 0.3270 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18935\n",
      "Epoch 12/20\n",
      "1408/1408 [==============================] - 291s 207ms/step - loss: 0.2098 - acc: 0.9048 - val_loss: 0.1931 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18935\n",
      "Epoch 13/20\n",
      "1408/1408 [==============================] - 294s 209ms/step - loss: 0.1988 - acc: 0.9119 - val_loss: 0.7141 - val_acc: 0.7756\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18935\n",
      "Epoch 14/20\n",
      "1408/1408 [==============================] - 283s 201ms/step - loss: 0.2116 - acc: 0.9091 - val_loss: 0.2526 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18935\n",
      "Epoch 15/20\n",
      "1408/1408 [==============================] - 284s 202ms/step - loss: 0.1924 - acc: 0.9148 - val_loss: 0.2519 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18935\n",
      "Epoch 16/20\n",
      "1408/1408 [==============================] - 288s 204ms/step - loss: 0.1959 - acc: 0.9077 - val_loss: 0.1825 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.18935 to 0.18248, saving model to ./saved-models/achitecture-02.hdf5\n",
      "Epoch 17/20\n",
      "1408/1408 [==============================] - 287s 204ms/step - loss: 0.1966 - acc: 0.9162 - val_loss: 0.3343 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18248\n",
      "Epoch 18/20\n",
      "1408/1408 [==============================] - 286s 203ms/step - loss: 0.1917 - acc: 0.9233 - val_loss: 0.8358 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18248\n",
      "Epoch 19/20\n",
      "1408/1408 [==============================] - 283s 201ms/step - loss: 0.1818 - acc: 0.9126 - val_loss: 0.6518 - val_acc: 0.7670\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18248\n",
      "Epoch 20/20\n",
      "1408/1408 [==============================] - 289s 206ms/step - loss: 0.1911 - acc: 0.9141 - val_loss: 0.6686 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18248\n"
     ]
    }
   ],
   "source": [
    "duration_training = train_single_model(model, \n",
    "                                       best_model_filepath, \n",
    "                                       train_tensors, y_train, \n",
    "                                       valid_tensors, y_validate, \n",
    "                                       training_epochs, \n",
    "                                       batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. loading best weights ..\n"
     ]
    }
   ],
   "source": [
    "print(\".. loading best weights ..\")\n",
    "\n",
    "model.load_weights(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/440 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Test data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:40<00:00, 11.33it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Test data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "test_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(test_tensors)]\n",
    "\n",
    "test_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1408 [00:00<03:02,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Training data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1408/1408 [02:04<00:00, 11.29it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Training data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "train_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(train_tensors)]\n",
    "\n",
    "train_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/352 [00:00<00:49,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. testing the model on Validation data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:31<00:00, 11.30it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\".. testing the model on Validation data ..\")\n",
    "section_start_time = datetime.datetime.utcnow()\n",
    "\n",
    "validation_data_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in tqdm(valid_tensors)]\n",
    "\n",
    "validation_data_predictions_time = (datetime.datetime.utcnow() - section_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "TIMING SUMMARY:\n",
      "\n",
      "loading duration: 26.1 seconds\n",
      "training duration: 8913.1 seconds\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON TEST DATA:\n",
      "\n",
      "predict duration: 40.5 seconds\n",
      "all:  440\n",
      "all_positives:  81\n",
      "all_negatives:  359\n",
      "true_positives:  71\n",
      "true_negatives:  343\n",
      "false_positives:  16\n",
      "false_negatives:  10\n",
      "RECALL: 0.88\n",
      "SPECIFICITY: 0.96\n",
      "ACCURACY: 0.94\n",
      "PRECISION: 0.82\n",
      "F1 SCORE: 0.85\n",
      "FP RATE / ERROR I: 0.04\n",
      "FN RATE / ERROR II: 0.12\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON TRAIN DATA:\n",
      "\n",
      "predict duration: 124.7 seconds\n",
      "all:  1408\n",
      "all_positives:  316\n",
      "all_negatives:  1092\n",
      "true_positives:  255\n",
      "true_negatives:  1047\n",
      "false_positives:  45\n",
      "false_negatives:  61\n",
      "RECALL: 0.81\n",
      "SPECIFICITY: 0.96\n",
      "ACCURACY: 0.92\n",
      "PRECISION: 0.85\n",
      "F1 SCORE: 0.83\n",
      "FP RATE / ERROR I: 0.04\n",
      "FN RATE / ERROR II: 0.19\n",
      "________________________________________________________\n",
      "MODEL PERFORMANCE ON VALIDATION DATA:\n",
      "\n",
      "predict duration: 31.2 seconds\n",
      "all:  352\n",
      "all_positives:  66\n",
      "all_negatives:  286\n",
      "true_positives:  49\n",
      "true_negatives:  274\n",
      "false_positives:  12\n",
      "false_negatives:  17\n",
      "RECALL: 0.74\n",
      "SPECIFICITY: 0.96\n",
      "ACCURACY: 0.92\n",
      "PRECISION: 0.80\n",
      "F1 SCORE: 0.77\n",
      "FP RATE / ERROR I: 0.04\n",
      "FN RATE / ERROR II: 0.26\n"
     ]
    }
   ],
   "source": [
    "print(\"________________________________________________________\")\n",
    "print(\"TIMING SUMMARY:\\n\")\n",
    "print(\"loading duration: {0:.1f} seconds\".format(duration_loading))\n",
    "print(\"training duration: {0:.1f} seconds\".format(duration_training))\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON TEST DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(test_data_predictions_time))\n",
    "false_positive_images, false_negative_images = summarize_model_performance(X_test, y_test, test_data_predictions)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON TRAIN DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(train_data_predictions_time))\n",
    "_, _ = summarize_model_performance(X_train, y_train, train_data_predictions)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "print(\"MODEL PERFORMANCE ON VALIDATION DATA:\\n\")\n",
    "print(\"predict duration: {0:.1f} seconds\".format(validation_data_predictions_time))\n",
    "_, _ = summarize_model_performance(X_validate, y_validate, validation_data_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Positives (first 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div width='100%'><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831138798001-266.jpg:          <img src=\"./data-images/5831138798001-266.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-531.jpg:          <img src=\"./data-images/5831137888001-531.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831138798001-42.jpg:          <img src=\"./data-images/5831138798001-42.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833096735001-762.jpg:          <img src=\"./data-images/5833096735001-762.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139883001-314.jpg:          <img src=\"./data-images/5831139883001-314.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-660.jpg:          <img src=\"./data-images/5831135989001-660.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-2231.jpg:          <img src=\"./data-images/5833078851001-2231.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-160.jpg:          <img src=\"./data-images/5831137888001-160.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833084561001-1734.jpg:          <img src=\"./data-images/5833084561001-1734.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139883001-2158.jpg:          <img src=\"./data-images/5831139883001-2158.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831138807001-1266.jpg:          <img src=\"./data-images/5831138807001-1266.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-801.jpg:          <img src=\"./data-images/5833078851001-801.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831139886001-1272.jpg:          <img src=\"./data-images/5831139886001-1272.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-930.jpg:          <img src=\"./data-images/5833078851001-930.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-631.jpg:          <img src=\"./data-images/5831135989001-631.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833096735001-1238.jpg:          <img src=\"./data-images/5833096735001-1238.jpg\" style=\"display:inline-block;\"> </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(false_positive_images[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Negatives (first 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div width='100%'><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833090951001-1225.jpg:          <img src=\"./data-images/5833090951001-1225.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831135989001-1849.jpg:          <img src=\"./data-images/5831135989001-1849.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831138807001-79.jpg:          <img src=\"./data-images/5831138807001-79.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833078851001-1646.jpg:          <img src=\"./data-images/5833078851001-1646.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-965.jpg:          <img src=\"./data-images/5831137888001-965.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833084561001-293.jpg:          <img src=\"./data-images/5833084561001-293.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833090951001-1998.jpg:          <img src=\"./data-images/5833090951001-1998.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833096735001-2176.jpg:          <img src=\"./data-images/5833096735001-2176.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5831137888001-1862.jpg:          <img src=\"./data-images/5831137888001-1862.jpg\" style=\"display:inline-block;\"> </div><div style=\"font-size: 10px; display:inline-block; width: 270px; border:1px solid black\">          ./data-images/5833096735001-1793.jpg:          <img src=\"./data-images/5833096735001-1793.jpg\" style=\"display:inline-block;\"> </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(false_negative_images[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
